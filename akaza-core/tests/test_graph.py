import logging
from tempfile import TemporaryDirectory
import sys
import pathlib

sys.path.insert(0, str(pathlib.Path(__file__).parent.joinpath('../../akaza-data/').absolute().resolve()))

import pytest
from akaza.node import Node
from akaza.graph_resolver import GraphResolver
from akaza.user_language_model import UserLanguageModel
from akaza_data.systemlm_loader import BinaryDict, SystemUnigramLM, SystemBigramLM

system_unigram_lm = SystemUnigramLM()
system_unigram_lm.load("../akaza-data/akaza_data/data/lm_v2_1gram.trie")

system_bigram_lm = SystemBigramLM()
system_bigram_lm.load("../akaza-data/akaza_data/data/lm_v2_2gram.trie")


tmpdir = TemporaryDirectory()
user_language_model = UserLanguageModel(tmpdir.name)

system_dict = BinaryDict()
system_dict.load("../akaza-data/akaza_data/data/system_dict.trie")

single_term = BinaryDict()
single_term.load("../akaza-data/akaza_data/data/single_term.trie")

logging.basicConfig(level=logging.DEBUG)


@pytest.mark.parametrize('src, expected', [
    # Wnn ã§æœ‰åãªãƒ•ãƒ¬ãƒ¼ã‚ºã€‚
    ('ã‚ãŸã—ã®ãªã¾ãˆã¯ãªã‹ã®ã§ã™', 'ç§ã®åå‰ã¯ä¸­é‡ã§ã™'),
    # ã‚«ã‚¿ã‚«ãƒŠèªã®å‡¦ç†ãŒå‡ºæ¥ã¦ã„ã‚‹ã“ã¨ã€‚
    ('ã‚ãƒ¼ã©', 'ãƒ¯ãƒ¼ãƒ‰'),
    ('ã«ã»ã‚“', 'æ—¥æœ¬'),
    ('ã‚„ã‚„ã“ã—ã„', 'ã‚„ã‚„ã“ã—ã„'),
    ('ã‚€ãšã‹ã—ããªã„', 'é›£ã—ãç„¡ã„'),
    ('ããã‚“', 'æ—¢å­˜'),
    ('ã®ãã¾ã—ã„', 'æœ›ã¾ã—ã„'),
    ('ã“ã†ã„ã†', 'ã“ã†ã„ã†'),
    ('ã¯ã‚„ãã¡', 'æ—©å£'),
    # ('ã©ã£ããµãƒ¼ã§ãƒã‚“ãã—ã¥ã‚‰ã„', 'ãƒ‰ãƒƒã‚°ãƒ•ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ä»•è¾›ã„'),
    ('ã—ã‚‡ã†ãŒã£ã“ã†', 'å°å­¦æ ¡'),
    ('ã’ã™ã¨ã ã‘', 'ã‚²ã‚¹ãƒˆã ã‘'),
    ('ãœã‚“ã¶ã§ã¦ã‚‹ã‚„ã¤', 'å…¨éƒ¨ã§ã¦ã‚‹ã‚„ã¤'),
    ('ãˆã‚‰ã¹ã‚‹', 'é¸ã¹ã‚‹'),
    ('ã‚ãŸã—ã ã‚ˆ', 'ã‚ãŸã—ã ã‚ˆ'),
    # ('ã«ã»ã‚“ã”ã˜ã‚‡ã†ã»ã†', 'æ—¥æœ¬èªæƒ…å ±'),
    # ('ãã†ã¿ãŸã„ã§ã™ã­', 'ãã†ã¿ãŸã„ã§ã™ã­'),
    ('ãã‚ã¤ã®ã‚„ã„ã°', 'é¬¼æ»…ã®åˆƒ'),
    ('ã‚Œã„ã‚', 'ä»¤å’Œ'),
])
def test_expected(src, expected):
    resolver = GraphResolver(
        user_language_model=user_language_model,
        system_unigram_lm=system_unigram_lm,
        system_bigram_lm=system_bigram_lm,
        normal_dicts=[system_dict],
        single_term_dicts=[single_term],
    )

    ht = dict(resolver.lookup(src))
    graph = resolver.graph_construct(src, ht)

    clauses = resolver.viterbi(graph)
    print(graph)
    got = ''.join([clause[0].word for clause in clauses])

    assert got == expected


def test_wnn():
    src = 'ã‚ãŸã—ã®ãªã¾ãˆã¯ãªã‹ã®ã§ã™'
    expected = 'ç§ã®åå‰ã¯ä¸­é‡ã§ã™'

    resolver = GraphResolver(
        user_language_model=user_language_model,
        system_unigram_lm=system_unigram_lm,
        system_bigram_lm=system_bigram_lm,
        normal_dicts=[system_dict],
        single_term_dicts=[single_term],
    )
    ht = dict(resolver.lookup(src))
    graph = resolver.graph_construct(src, ht)

    clauses = resolver.viterbi(graph)
    got = ''.join([clause[0].word for clause in clauses])

    # print(graph)

    assert got == expected


def test_graph_extend():
    src = 'ã¯ãªã‹'
    resolver = GraphResolver(
        user_language_model=user_language_model,
        system_unigram_lm=system_unigram_lm,
        system_bigram_lm=system_bigram_lm,
        normal_dicts=[system_dict],
        single_term_dicts=[single_term],
    )
    ht = dict(resolver.lookup(src))
    # (0,2) ã®æ–‡ç¯€ã‚’å¼·åˆ¶æŒ‡å®šã™ã‚‹
    graph = resolver.graph_construct(src, ht, [
        slice(0, 2),
        slice(2, 3)
    ])
    assert 1 not in graph.d


# ã€Œã²ã‚‡ã„ãƒ¼ã€ã®ã‚ˆã†ãªè¾æ›¸ã«ç™»éŒ²ã•ã‚Œã¦ã„ãªã„å˜èªã«å¯¾ã—ã¦ã€ã‚«ã‚¿ã‚«ãƒŠå€™è£œã‚’æä¾›ã™ã¹ãã€‚
def test_katakana_candidates():
    src = 'ã²ã‚‡ã„ãƒ¼'
    resolver = GraphResolver(
        user_language_model=user_language_model,
        system_unigram_lm=system_unigram_lm,
        system_bigram_lm=system_bigram_lm,
        normal_dicts=[system_dict],
        single_term_dicts=[single_term],
    )
    ht = dict(resolver.lookup(src))
    for k, v in ht.items():
        print(f"{k}:{v}")
    graph = resolver.graph_construct(src, ht, [
        slice(0, 4)
    ])
    print(graph)

    clauses = resolver.viterbi(graph)
    print(clauses)
    got = '/'.join([node.word for node in clauses[0]])

    assert got == 'ã²ã‚‡ã„ãƒ¼/ãƒ’ãƒ§ã‚¤ãƒ¼/hyoiãƒ¼/ï½ˆï½™ï½ï½‰ãƒ¼'


# ã€Œã²ã‚‡ã„ãƒ¼ã€ã®ã‚ˆã†ãªè¾æ›¸ã«ç™»éŒ²ã•ã‚Œã¦ã„ãªã„å˜èªã«å¯¾ã—ã¦ã€ã‚«ã‚¿ã‚«ãƒŠå€™è£œã‚’æä¾›ã™ã¹ãã€‚
def test_emoji_candidates():
    src = 'ã™ã—'
    resolver = GraphResolver(
        user_language_model=user_language_model,
        system_unigram_lm=system_unigram_lm,
        system_bigram_lm=system_bigram_lm,
        normal_dicts=[system_dict],
        single_term_dicts=[single_term],
    )
    ht = dict(resolver.lookup(src))
    for k, v in ht.items():
        print(f"{k}:{v}")
    graph = resolver.graph_construct(src, ht, [
    ])
    print(graph)

    clauses = resolver.viterbi(graph)
    print(clauses)
    got = '/'.join([node.word for node in clauses[0]])

    assert 'ğŸ£' in got


# ã€Œã²ã‚‡ã„ãƒ¼ã€ã®ã‚ˆã†ãªè¾æ›¸ã«ç™»éŒ²ã•ã‚Œã¦ã„ãªã„å˜èªã«å¯¾ã—ã¦ã€ã‚«ã‚¿ã‚«ãƒŠå€™è£œã‚’æä¾›ã™ã¹ãã€‚
def test_katakana_candidates_for_unknown_word():
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼è¨€èªãƒ¢ãƒ‡ãƒ«ã§ã€Œãƒ’ãƒ§ã‚¤ãƒ¼ã€ã®ã‚³ã‚¹ãƒˆã‚’é«˜ã‚ã¦ãŠãã€‚
    my_tmpdir = TemporaryDirectory()
    my_user_language_model = UserLanguageModel(my_tmpdir.name)
    my_user_language_model.add_entry(
        [Node(start_pos=0, word='ãƒ’ãƒ§ã‚¤ãƒ¼', yomi='ã²ã‚‡ã„ãƒ¼')]
    )
    my_user_language_model.add_entry(
        [Node(start_pos=0, word='ãƒ’ãƒ§ã‚¤ãƒ¼', yomi='ã²ã‚‡ã„ãƒ¼')]
    )
    my_user_language_model.add_entry(
        [Node(start_pos=0, word='ãƒ’ãƒ§ã‚¤ãƒ¼', yomi='ã²ã‚‡ã„ãƒ¼')]
    )
    my_user_language_model.add_entry(
        [Node(start_pos=0, word='ãƒ’ãƒ§ã‚¤ãƒ¼', yomi='ã²ã‚‡ã„ãƒ¼')]
    )

    src = 'ã²ã‚‡ã„ãƒ¼'

    print(my_user_language_model.has_unigram_cost_by_yomi('ã²ã‚‡ã„ãƒ¼'))

    resolver = GraphResolver(
        user_language_model=my_user_language_model,
        system_unigram_lm=system_unigram_lm,
        system_bigram_lm=system_bigram_lm,
        normal_dicts=[system_dict],
        single_term_dicts=[single_term],
    )
    ht = dict(resolver.lookup(src))
    graph = resolver.graph_construct(src, ht)
    assert 'ã²ã‚‡ã„ãƒ¼' in set([node.yomi for node in graph.all_nodes()])
    # print(graph)

    clauses = resolver.viterbi(graph)
    print(graph.d[4])
    got = '/'.join([node.word for node in clauses[0]])

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼è¨€èªã‚‚ã§ã‚‹ã«ã‚‚ã¨ã„ã¥ã„ã¦ã€ãƒ’ãƒ§ã‚¤ãƒ¼ã®ã‚¹ã‚³ã‚¢ãŒã‚ãŒã£ã¦ä¸Šä½ã«ã§ã‚‹ã‚ˆã†ã«ãªã£ã¦ã„ã‚‹ã€‚
    assert got == 'ãƒ’ãƒ§ã‚¤ãƒ¼/ã²ã‚‡ã„ãƒ¼'
