# 2023-01-24(Tue)

* 設定画面を gtk4-rs で実装した。

# 2022-12-23(Fri)

 * Started development, again.
 * akaza can't start the process... why?
 * /usr/local/lib に libakaza.so を入れているが、、あんまりお行儀が良くないかもね。

# 2020-09-17(Thu)

 * システム辞書に `/` が入っていない、いらないものを消す。
 * システム言語モデルについて、順番を逆にしよう。
   * 逆にしてみた。
   * 戻した。
 * ヒョイーが変換できるようになった。

# 2020-09-16(Wed)

 * 「わたし」の変換結果に「私」が二個含まれてしまう。。なぜだ。
   * なおした。

* 言語モデルファイルのサイズをもう少し小さくしたい。50MB をきるようにしたい。現状↓

-rw-r--r-- 1 tokuhirom tokuhirom 5.5M Sep 14 18:57 system_dict.trie
-rw-r--r-- 1 tokuhirom tokuhirom  51M Sep 16 00:38 system_language_model.trie

 * `<nowiki>` 記法をちゃんと消すようにしたい。

# 2020-09-15(Tue)

Compare DAWG and marisa-trie.

    -rw-r--r-- 1 tokuhirom tokuhirom  37M Sep 15 00:46 system_dict.dawg
    -rw-r--r-- 1 tokuhirom tokuhirom 5.5M Sep 14 18:57 system_dict.trie
    -rw-r--r-- 1 tokuhirom tokuhirom 261M Sep 15 00:52 system_language_model.dawg
    -rw-r--r-- 1 tokuhirom tokuhirom  51M Sep 15 00:52 system_language_model.trie

# 2020-09-14(Mon)

* comb を akaza に改名した。
* ibus 関連部分とそれ以外を分離する。以下のようなモジュール構成を目指す。
 * ibus-akaza: ibus 連動部分。
 * akaza-core: 変換コアエンジン。ibus 関連部分と独立させることにより、fcitx との連動を可能にすることを目指す
 * skkdictutils: SKK 辞書関連ユーティリティライブラリ。単独利用可能なようにパッケージングし、単独レポジトリに独立させる予定。
 * akaza-data : システム辞書/システム言語モデル

# 2020-09-13(Sun)

* Rust で書き直そうかなぁ。。
 * fcitx とかに組み込むことを考えると、python だと不便なことも多い
 * マシン負荷を考えると Rust の方がよい。
* Rust で書き直すの、marisa-trie のマッピングとか考えるとめんどくさくて微妙そう。

# 2020-09-12(Sat)

* bigram ベースのユーザー辞書を実装した。
* kytea では、平仮名を細かく割りすぎかもしれない。
 * 例えば、kytea は 'そうですね' を `そう/副詞/そう で/助動詞/で す/語尾/す ね/助詞/ね` にするが、これはちょっと細かくわりすぎ。
 * jawiki.vocab は 297396 行あるが、これも圧縮可能かもしれない?
 * kytea から得られた結果をもとに、平仮名を連結して ngram を作成したが、この結果は惨憺たるものであった。
* DONE: 文節を伸ばす機能が死んでいる。
* ユーザー辞書を設定できるようにしたい。
  * ~/.config/ibus-akaza/user-dict.json のなかに設定をいれる。
  * `path/to/dict.txt;format=skk;charset=euc-jp` みたいなフォーマットでいいかなぁ。。JSONでもいいかな。。
  * 思ったより、簡単に実装できそう。

# 2020-09-11(Fri)

* 文節の区切り箇所を変更できるようになった。
* TODO: 長文を一気に入力しようとすると、IDEA が落ちる問題は継続。
* DONE: 大文字を最初に入れた場合は、アルファベットを優先すべき。
* UI 改善を実施。かなりよくなった。 変換キーをおさない限りは、変換されなくなった。

# 2020-09-10(Thu)

* TODO: "b" みたいな一文字のアルファベットを変換した場合、βってデルのはおかしいぞ。
* DONE: "nadowwwwwww" って入れた時の挙動がおかしいぞ！
* "いいね" の変換結果は、言い値じゃなくて「いいね」が第一候補にでてきてほしいなぁ。
  * そういう、口語表現が苦手なように見える。現在の実装では。
  * 実装というか、元文書が wikipedia だから、というのはあるけれど。。
* DONE: 変換候補が、ちゃんと選択されていない。
  * なおした。
* DONE: 平仮名候補が二回ずつでてくる問題
  * 重複排除ロジックを graph.py に入れた。

# 2020-09-09(Wed)

 * DONE: ニホン という単語を変換できない。 これは解決。
   * mecab は常に日本を、ニッポンとパースするので、 model に 日本/ニッポンしか登録されない
   * kytea をつかった方がいいかもしれない。
    * kytea ベースにした。「ニホン」が変換できない問題は解決した。
* DONE: 長い文章を入力した場合に、Viterbi アルゴリズムの処理時間が長過ぎる。
  * 辞書に重複登録されている単語をけして大夫ましになった
* DONE: 語尾の子音を処理してやる。 "ウケるwwww" みたいなかきかたができるようになった。
* DONE: "ヤヤコシイ" の変換結果がおかしい 'やや濃しい' になってしまう。
  * このあたりは、平仮名辞書がないと無理かもしれない。。
  * ひらがな辞書は、`jawiki.vocab` から生成可能か
    * 生成するようにした。
    * よく考えると、`jawiki.vocab` をまるごとシステム辞書としてしまって良いのかもしれない。
      * 実際に、そのようにしてみた。
      * これで、変換効率が高丸と呼いのだが。
        * "たかまるとよいのだが" がちゃんと変換できない。
* DONE: 辞書のマージができるようになったのはよかったが、同じ候補が複数回でているようだ。
* 再起動時に、辞書のキャッシュがきかなくなる理由がわかった。
  * 辞書を `install -p` にしてないから、毎回タイムスタンプが更新されているだけであった。
* DONE: zh で矢印が入らなくなった。謎。あぁ。。わかった
  * 子音の処理だ。

